{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0cf0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port', '0'). \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "appName(\"Spark\").\\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6aa7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a47c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147a7d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"emp_id\", IntegerType(), True),\n",
    "    StructField(\"emp_name\", StringType(), True),\n",
    "    StructField(\"emp_gender\", StringType(), True),\n",
    "    StructField(\"emp_age\", IntegerType(), True),\n",
    "    StructField(\"emp_salary\", IntegerType(), True),\n",
    "    StructField(\"emp_manager\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069d68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, \"Arjun Patel\", \"Male\", 30, 60000, \"Aarav Sharma\"),\n",
    "    (2, \"Aarav Sharma\", \"Male\", 28, 55000, \"Zara Singh\"),\n",
    "    (3, \"Zara Singh\", \"Female\", 35, 70000, \"Arjun Patel\"),\n",
    "    (4, \"Priya Reddy\", \"Female\", 32, 65000, \"Aarav Sharma\"),\n",
    "    (1, \"Arjun Patel\", \"Male\", 30, 60000, \"Aarav Sharma\"),\n",
    "    (6, \"Naina Verma\", \"Female\", 31, 72000, \"Arjun Patel\"),\n",
    "    (1, \"Arjun Patel\", \"Male\", 30, 60000, \"Aarav Sharma\"),\n",
    "    (4, \"Priya Reddy\", \"Female\", 32, 65000, \"Aarav Sharma\"),\n",
    "    (5, \"Aditya Kapoor\", \"Male\", 28, 58000, \"Zara Singh\"),\n",
    "    (10, \"Anaya Joshi\", \"Female\", 27, 59000, \"Aarav Sharma\"),\n",
    "    (11, \"Rohan Malhotra\", \"Male\", 36, 73000, \"Zara Singh\"),\n",
    "    (3, \"Zara Singh\", \"Female\", 35, 70000, \"Arjun Patel\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d50a8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.createDataFrame(data,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ecbb4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8aefd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df=df.groupBy(\"emp_id\").agg(count(\"*\")).alias(\"count_emp\").filter(col(\"count(1)\")>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6de30eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|emp_id|count(1)|\n",
      "+------+--------+\n",
      "|     1|       3|\n",
      "|     3|       2|\n",
      "|     4|       2|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f19cf279",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_df=df.groupby(df.columns).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce9bdf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----------+-------+----------+------------+\n",
      "|emp_id|   emp_name|emp_gender|emp_age|emp_salary| emp_manager|\n",
      "+------+-----------+----------+-------+----------+------------+\n",
      "|     1|Arjun Patel|      Male|     30|     60000|Aarav Sharma|\n",
      "|     3| Zara Singh|    Female|     35|     70000| Arjun Patel|\n",
      "|     4|Priya Reddy|    Female|     32|     65000|Aarav Sharma|\n",
      "+------+-----------+----------+-------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dup_df.filter(col(\"count\")>1).orderBy(\"emp_id\").drop(\"count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5fe4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8ed781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e4fa477",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec=Window.partitionBy(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10973dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_df=df.withColumn(\"count\",count(col(\"emp_id\")).over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c85b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=window_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a7eadff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------+-------+----------+------------+\n",
      "|emp_id|      emp_name|emp_gender|emp_age|emp_salary| emp_manager|\n",
      "+------+--------------+----------+-------+----------+------------+\n",
      "|     1|   Arjun Patel|      Male|     30|     60000|Aarav Sharma|\n",
      "|     2|  Aarav Sharma|      Male|     28|     55000|  Zara Singh|\n",
      "|     3|    Zara Singh|    Female|     35|     70000| Arjun Patel|\n",
      "|     4|   Priya Reddy|    Female|     32|     65000|Aarav Sharma|\n",
      "|     5| Aditya Kapoor|      Male|     28|     58000|  Zara Singh|\n",
      "|     6|   Naina Verma|    Female|     31|     72000| Arjun Patel|\n",
      "|    10|   Anaya Joshi|    Female|     27|     59000|Aarav Sharma|\n",
      "|    11|Rohan Malhotra|      Male|     36|     73000|  Zara Singh|\n",
      "+------+--------------+----------+-------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.orderBy(\"emp_id\").drop(\"count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed996abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Question 2: Union and Union All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "035d4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b96bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1=[Row(employee_name=\"Alice\", employee_gender=\"F\", employee_salary=70000),Row(employee_name=\"Bob\", employee_gender=\"M\", employee_salary=80000),\n",
    "         Row(employee_name=\"Charlie\", employee_gender=\"M\", employee_salary=55000),\n",
    "         Row(employee_name=\"David\", employee_gender=\"M\", employee_salary=45000),\n",
    "         Row(employee_name=\"Eve\", employee_gender=\"F\", employee_salary=50000),\n",
    "          Row(employee_name=\"Eve\", employee_gender=\"F\", employee_salary=50000)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee7a6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = [Row(employee_name=\"Frank\", employee_gender=\"M\", employee_salary=60000),\n",
    "         Row(employee_name=\"Grace\", employee_gender=\"F\", employee_salary=65000),\n",
    "         Row(employee_name=\"Hannah\", employee_gender=\"F\", employee_salary=70000),\n",
    "         Row(employee_name=\"Ian\", employee_gender=\"M\", employee_salary=48000),\n",
    "         Row(employee_name=\"Jill\", employee_gender=\"F\", employee_salary=53000),\n",
    "          Row(employee_name=\"Eve\", employee_gender=\"F\", employee_salary=50000)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8d367fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=spark.createDataFrame(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4836b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=spark.createDataFrame(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e959786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=df1.union(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f2afa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+---------------+\n",
      "|employee_name|employee_gender|employee_salary|\n",
      "+-------------+---------------+---------------+\n",
      "|        Alice|              F|          70000|\n",
      "|          Bob|              M|          80000|\n",
      "|      Charlie|              M|          55000|\n",
      "|        David|              M|          45000|\n",
      "|          Eve|              F|          50000|\n",
      "|          Eve|              F|          50000|\n",
      "|        Frank|              M|          60000|\n",
      "|        Grace|              F|          65000|\n",
      "|       Hannah|              F|          70000|\n",
      "|          Ian|              M|          48000|\n",
      "|         Jill|              F|          53000|\n",
      "|          Eve|              F|          50000|\n",
      "+-------------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ded902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## unique records while using union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6b89fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique=result_df.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d54c97f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+---------------+\n",
      "|employee_name|employee_gender|employee_salary|\n",
      "+-------------+---------------+---------------+\n",
      "|Eve          |F              |50000          |\n",
      "|Frank        |M              |60000          |\n",
      "|Hannah       |F              |70000          |\n",
      "|David        |M              |45000          |\n",
      "|Bob          |M              |80000          |\n",
      "|Alice        |F              |70000          |\n",
      "|Jill         |F              |53000          |\n",
      "|Charlie      |M              |55000          |\n",
      "|Ian          |M              |48000          |\n",
      "|Grace        |F              |65000          |\n",
      "+-------------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_unique.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6def1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If we have diff schema then we need to use unionByName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6289c690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g02.itversity.com:38915\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff929585630>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ec5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25715d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data = [\n",
    "    (101, \"Varun\", \"Sales\", 75000),\n",
    "    (102, \"Alia\", \"HR\", 46000),\n",
    "    (103, \"David\", \"IT\", 55000),\n",
    "    (104, \"Steve\", \"Sales\", 75000),\n",
    "    (105, \"Soham\", \"HR\", 46000),\n",
    "    (106, \"Kiron\", \"IT\", 50000),\n",
    "    (107, \"Dhoni\", \"Sales\", 68000),\n",
    "    (108, \"Tiger\", \"HR\", 45000),\n",
    "    (109, \"Rock\", \"IT\", 53000),\n",
    "    (110, \"Khali\", \"Sales\", 75000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fccc314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_schema=StructType([\n",
    "    StructField(\"emp_id\",IntegerType(),True),\n",
    "    StructField(\"emp_name\",StringType(),True),\n",
    "    StructField(\"emp_dept\",StringType(),True),\n",
    "    StructField(\"emp_sal\",LongType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "086882a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df=spark.createDataFrame(emp_data,emp_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c40f512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+-------+\n",
      "|emp_id|emp_name|emp_dept|emp_sal|\n",
      "+------+--------+--------+-------+\n",
      "|   101|   Varun|   Sales|  75000|\n",
      "|   102|    Alia|      HR|  46000|\n",
      "|   103|   David|      IT|  55000|\n",
      "|   104|   Steve|   Sales|  75000|\n",
      "|   105|   Soham|      HR|  46000|\n",
      "|   106|   Kiron|      IT|  50000|\n",
      "|   107|   Dhoni|   Sales|  68000|\n",
      "|   108|   Tiger|      HR|  45000|\n",
      "|   109|    Rock|      IT|  53000|\n",
      "|   110|   Khali|   Sales|  75000|\n",
      "+------+--------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5438d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaf1fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec=Window.partitionBy(\"emp_dept\").orderBy(col(\"emp_sal\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a33c5eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e00a2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+-------+----+\n",
      "|emp_id|emp_name|emp_dept|emp_sal|Rank|\n",
      "+------+--------+--------+-------+----+\n",
      "|   110|   Khali|   Sales|  75000|   1|\n",
      "|   101|   Varun|   Sales|  75000|   1|\n",
      "|   104|   Steve|   Sales|  75000|   1|\n",
      "|   107|   Dhoni|   Sales|  68000|   4|\n",
      "|   102|    Alia|      HR|  46000|   1|\n",
      "|   105|   Soham|      HR|  46000|   1|\n",
      "|   108|   Tiger|      HR|  45000|   3|\n",
      "|   103|   David|      IT|  55000|   1|\n",
      "|   109|    Rock|      IT|  53000|   2|\n",
      "|   106|   Kiron|      IT|  50000|   3|\n",
      "+------+--------+--------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank_df=emp_df.withColumn(\"Rank\",rank().over(window_spec))\n",
    "rank_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3ecf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dense_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4cfd9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+-------+----+\n",
      "|emp_id|emp_name|emp_dept|emp_sal|Rank|\n",
      "+------+--------+--------+-------+----+\n",
      "|   101|   Varun|   Sales|  75000|   1|\n",
      "|   104|   Steve|   Sales|  75000|   1|\n",
      "|   110|   Khali|   Sales|  75000|   1|\n",
      "|   107|   Dhoni|   Sales|  68000|   2|\n",
      "|   102|    Alia|      HR|  46000|   1|\n",
      "|   105|   Soham|      HR|  46000|   1|\n",
      "|   108|   Tiger|      HR|  45000|   2|\n",
      "|   103|   David|      IT|  55000|   1|\n",
      "|   109|    Rock|      IT|  53000|   2|\n",
      "|   106|   Kiron|      IT|  50000|   3|\n",
      "+------+--------+--------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dense_rank_df=emp_df.withColumn(\"Rank\",dense_rank().over(window_spec))\n",
    "dense_rank_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b8523a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Row Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84207511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+-------+----+\n",
      "|emp_id|emp_name|emp_dept|emp_sal|Rank|\n",
      "+------+--------+--------+-------+----+\n",
      "|   110|   Khali|   Sales|  75000|   1|\n",
      "|   101|   Varun|   Sales|  75000|   2|\n",
      "|   104|   Steve|   Sales|  75000|   3|\n",
      "|   107|   Dhoni|   Sales|  68000|   4|\n",
      "|   102|    Alia|      HR|  46000|   1|\n",
      "|   105|   Soham|      HR|  46000|   2|\n",
      "|   108|   Tiger|      HR|  45000|   3|\n",
      "|   103|   David|      IT|  55000|   1|\n",
      "|   109|    Rock|      IT|  53000|   2|\n",
      "|   106|   Kiron|      IT|  50000|   3|\n",
      "+------+--------+--------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row_number_df=emp_df.withColumn(\"Rank\",row_number().over(window_spec))\n",
    "row_number_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0097290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
